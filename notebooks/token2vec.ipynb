{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "import os\n",
    "sys.argv=['']\n",
    "del sys\n",
    "os.chdir(\"../\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import math\n",
    "import torch\n",
    "import numpy\n",
    "import pandas\n",
    "import logging\n",
    "import numpy as np\n",
    "from tslearn.metrics import dtw\n",
    "\n",
    "\n",
    "\n",
    "from IPython import embed\n",
    "from common import scikit_wrappers, data_preprocess \n",
    "from common.utils import print_to_json\n",
    "from common.dataloader import load_SMD_dataset, load_CSV_dataset\n",
    "from common.sliding import BatchSlidingWindow, WindowIterator\n",
    "from common.config import parse_arguments, set_logger, initialize_config\n",
    "\n",
    "\n",
    "args = parse_arguments()\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load config\n",
    "config_dir = \"./hypers/\" if not args[\"load\"] else args[\"load\"]\n",
    "params = initialize_config(config_dir, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp = data_preprocess.preprocessor()\n",
    "data_dict1 = load_CSV_dataset(params[\"path\"], dataset=\"[3]: 1583_295\")\n",
    "data_dict2 = load_CSV_dataset(params[\"path\"], dataset=\"[0]: 15449476_6265666\") \n",
    "data_dict1_disc = pp.discretize(data_dict1, mode=\"train\")\n",
    "data_dict2_disc = pp.discretize(data_dict2, mode=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_windows1, test_windows1 = data_preprocess.generate_windows(data_dict1, window_size=params[\"window_size\"])\n",
    "train_windows2, test_windows2 = data_preprocess.generate_windows(data_dict2, window_size=params[\"window_size\"])\n",
    "train_windows1_disc, test_windows1_disc = data_preprocess.generate_windows(data_dict1_disc, window_size=params[\"window_size\"])\n",
    "train_windows2_disc, test_windows2_disc = data_preprocess.generate_windows(data_dict2_disc, window_size=params[\"window_size\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_dict = load_CSV_dataset(params[\"path\"])\n",
    "data_dict_disc = pp.discretize(data_dict, mode=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_windows_disc, test_windows_disc = data_preprocess.generate_windows(data_dict_disc, window_size=params[\"window_size\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.0"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(test_windows_disc.cpu().numpy()[:,0,:].reshape(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "999.0"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(train_windows_disc.cpu().numpy()[:,0,:].reshape(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "seqs = train_windows_disc.cpu().numpy()[:,0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "seqs_str = [list(seq) for seq in seqs.astype(str)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-11-12 16:45:15,941 P53769 INFO 'pattern' package not found; tag filters are not available for English\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-11-12 16:51:24,908 P53769 INFO collecting all words and their counts\n",
      "2020-11-12 16:51:24,909 P53769 INFO PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2020-11-12 16:51:24,979 P53769 INFO PROGRESS: at sentence #10000, processed 450000 words, keeping 434 word types\n",
      "2020-11-12 16:51:25,048 P53769 INFO PROGRESS: at sentence #20000, processed 900000 words, keeping 540 word types\n",
      "2020-11-12 16:51:25,115 P53769 INFO PROGRESS: at sentence #30000, processed 1350000 words, keeping 583 word types\n",
      "2020-11-12 16:51:25,183 P53769 INFO PROGRESS: at sentence #40000, processed 1800000 words, keeping 609 word types\n",
      "2020-11-12 16:51:25,248 P53769 INFO PROGRESS: at sentence #50000, processed 2250000 words, keeping 636 word types\n",
      "2020-11-12 16:51:25,313 P53769 INFO collected 648 word types from a corpus of 2690100 raw words and 59780 sentences\n",
      "2020-11-12 16:51:25,315 P53769 INFO Loading a fresh vocabulary\n",
      "2020-11-12 16:51:25,316 P53769 INFO effective_min_count=1 retains 648 unique words (100% of original 648, drops 0)\n",
      "2020-11-12 16:51:25,317 P53769 INFO effective_min_count=1 leaves 2690100 word corpus (100% of original 2690100, drops 0)\n",
      "2020-11-12 16:51:25,319 P53769 INFO deleting the raw counts dictionary of 648 items\n",
      "2020-11-12 16:51:25,320 P53769 INFO sample=0.001 downsamples 174 most-common words\n",
      "2020-11-12 16:51:25,321 P53769 INFO downsampling leaves estimated 2136692 word corpus (79.4% of prior 2690100)\n",
      "2020-11-12 16:51:25,323 P53769 INFO estimated required memory for 648 words and 100 dimensions: 842400 bytes\n",
      "2020-11-12 16:51:25,324 P53769 INFO resetting layer weights\n",
      "2020-11-12 16:51:25,437 P53769 INFO training model with 4 workers on 648 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=45\n",
      "2020-11-12 16:51:26,444 P53769 INFO EPOCH 1 - PROGRESS: at 65.36% examples, 1388597 words/s, in_qsize 7, out_qsize 0\n",
      "2020-11-12 16:51:26,948 P53769 INFO worker thread finished; awaiting finish of 3 more threads\n",
      "2020-11-12 16:51:26,950 P53769 INFO worker thread finished; awaiting finish of 2 more threads\n",
      "2020-11-12 16:51:26,956 P53769 INFO worker thread finished; awaiting finish of 1 more threads\n",
      "2020-11-12 16:51:26,959 P53769 INFO worker thread finished; awaiting finish of 0 more threads\n",
      "2020-11-12 16:51:26,960 P53769 INFO EPOCH - 1 : training on 2690100 raw words (2136730 effective words) took 1.5s, 1406151 effective words/s\n",
      "2020-11-12 16:51:27,968 P53769 INFO EPOCH 2 - PROGRESS: at 66.10% examples, 1407479 words/s, in_qsize 7, out_qsize 0\n",
      "2020-11-12 16:51:28,473 P53769 INFO worker thread finished; awaiting finish of 3 more threads\n",
      "2020-11-12 16:51:28,476 P53769 INFO worker thread finished; awaiting finish of 2 more threads\n",
      "2020-11-12 16:51:28,478 P53769 INFO worker thread finished; awaiting finish of 1 more threads\n",
      "2020-11-12 16:51:28,486 P53769 INFO worker thread finished; awaiting finish of 0 more threads\n",
      "2020-11-12 16:51:28,487 P53769 INFO EPOCH - 2 : training on 2690100 raw words (2135821 effective words) took 1.5s, 1405188 effective words/s\n",
      "2020-11-12 16:51:29,494 P53769 INFO EPOCH 3 - PROGRESS: at 64.99% examples, 1384391 words/s, in_qsize 7, out_qsize 0\n",
      "2020-11-12 16:51:30,001 P53769 INFO worker thread finished; awaiting finish of 3 more threads\n",
      "2020-11-12 16:51:30,006 P53769 INFO worker thread finished; awaiting finish of 2 more threads\n",
      "2020-11-12 16:51:30,007 P53769 INFO worker thread finished; awaiting finish of 1 more threads\n",
      "2020-11-12 16:51:30,016 P53769 INFO worker thread finished; awaiting finish of 0 more threads\n",
      "2020-11-12 16:51:30,017 P53769 INFO EPOCH - 3 : training on 2690100 raw words (2137336 effective words) took 1.5s, 1402142 effective words/s\n",
      "2020-11-12 16:51:31,025 P53769 INFO EPOCH 4 - PROGRESS: at 66.10% examples, 1406912 words/s, in_qsize 7, out_qsize 0\n",
      "2020-11-12 16:51:31,525 P53769 INFO worker thread finished; awaiting finish of 3 more threads\n",
      "2020-11-12 16:51:31,529 P53769 INFO worker thread finished; awaiting finish of 2 more threads\n",
      "2020-11-12 16:51:31,532 P53769 INFO worker thread finished; awaiting finish of 1 more threads\n",
      "2020-11-12 16:51:31,537 P53769 INFO worker thread finished; awaiting finish of 0 more threads\n",
      "2020-11-12 16:51:31,538 P53769 INFO EPOCH - 4 : training on 2690100 raw words (2136596 effective words) took 1.5s, 1410208 effective words/s\n",
      "2020-11-12 16:51:32,549 P53769 INFO EPOCH 5 - PROGRESS: at 65.36% examples, 1387245 words/s, in_qsize 7, out_qsize 0\n",
      "2020-11-12 16:51:33,066 P53769 INFO worker thread finished; awaiting finish of 3 more threads\n",
      "2020-11-12 16:51:33,068 P53769 INFO worker thread finished; awaiting finish of 2 more threads\n",
      "2020-11-12 16:51:33,077 P53769 INFO worker thread finished; awaiting finish of 1 more threads\n",
      "2020-11-12 16:51:33,080 P53769 INFO worker thread finished; awaiting finish of 0 more threads\n",
      "2020-11-12 16:51:33,081 P53769 INFO EPOCH - 5 : training on 2690100 raw words (2136527 effective words) took 1.5s, 1391513 effective words/s\n",
      "2020-11-12 16:51:33,081 P53769 INFO training on a 13450500 raw words (10683010 effective words) took 7.6s, 1397719 effective words/s\n"
     ]
    }
   ],
   "source": [
    "model = Word2Vec(sentences=seqs_str, size=100, window=params[\"window_size\"], min_count=1, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('999.0', 0.4464571475982666),\n",
       " ('749.0', 0.35341572761535645),\n",
       " ('73.0', 0.3297819197177887),\n",
       " ('659.0', 0.31378233432769775),\n",
       " ('124.0', 0.2960684895515442),\n",
       " ('408.0', 0.28490298986434937),\n",
       " ('195.0', 0.2616068720817566),\n",
       " ('142.0', 0.2444586157798767),\n",
       " ('409.0', 0.2392110526561737),\n",
       " ('125.0', 0.23146170377731323)]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(\"787.0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('122.0', 0.39886119961738586),\n",
       " ('116.0', 0.3243066668510437),\n",
       " ('49.0', 0.3088116943836212),\n",
       " ('452.0', 0.3022875189781189),\n",
       " ('23.0', 0.2951423227787018),\n",
       " ('512.0', 0.27868640422821045),\n",
       " ('97.0', 0.27154213190078735),\n",
       " ('364.0', 0.27152130007743835),\n",
       " ('764.0', 0.2674259543418884),\n",
       " ('494.0', 0.26684510707855225)]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(\"174.0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['216.0', '213.0', '361.0', '290.0', '198.0', '252.0', '463.0', '217.0', '291.0', '284.0', '373.0', '235.0', '270.0', '334.0', '274.0', '132.0', '368.0', '366.0', '232.0', '295.0', '229.0', '241.0', '297.0', '279.0', '276.0', '299.0', '194.0', '289.0', '778.0', '304.0', '818.0', '358.0', '347.0', '268.0', '330.0', '205.0', '220.0', '379.0', '314.0', '360.0', '307.0', '349.0', '233.0', '275.0', '313.0', '339.0', '282.0', '256.0', '390.0', '257.0', '271.0', '301.0', '331.0', '318.0', '239.0', '329.0', '320.0', '185.0', '231.0', '316.0', '221.0', '345.0', '323.0', '389.0', '238.0', '251.0', '364.0', '172.0', '164.0', '124.0', '262.0', '416.0', '303.0', '400.0', '261.0', '298.0', '223.0', '189.0', '338.0', '225.0', '199.0', '321.0', '296.0', '328.0', '125.0', '383.0', '327.0', '247.0', '272.0', '188.0', '322.0', '209.0', '287.0', '184.0', '211.0', '337.0', '375.0', '305.0', '309.0', '219.0', '161.0', '340.0', '319.0', '317.0', '310.0', '266.0', '336.0', '410.0', '250.0', '240.0', '177.0', '255.0', '265.0', '369.0', '393.0', '292.0', '294.0', '253.0', '254.0', '380.0', '371.0', '324.0', '242.0', '378.0', '148.0', '264.0', '353.0', '625.0', '658.0', '237.0', '286.0', '154.0', '249.0', '186.0', '359.0', '273.0', '246.0', '260.0', '409.0', '332.0', '248.0', '207.0', '288.0', '306.0', '354.0', '357.0', '441.0', '171.0', '280.0', '285.0', '196.0', '300.0', '215.0', '352.0', '350.0', '129.0', '344.0', '356.0', '311.0', '111.0', '200.0', '259.0', '167.0', '377.0', '365.0', '195.0', '197.0', '372.0', '346.0', '224.0', '414.0', '374.0', '206.0', '342.0', '212.0', '263.0', '267.0', '325.0', '367.0', '130.0', '204.0', '158.0', '269.0', '191.0', '277.0', '118.0', '343.0', '179.0', '426.0', '351.0', '315.0', '283.0', '419.0', '203.0', '140.0', '333.0', '355.0', '227.0', '234.0', '244.0', '278.0', '281.0', '362.0', '326.0', '236.0', '401.0', '341.0', '230.0', '187.0', '181.0', '192.0', '394.0', '135.0', '226.0', '293.0', '411.0', '335.0', '388.0', '146.0', '396.0', '468.0', '243.0', '162.0', '169.0', '182.0', '258.0', '173.0', '370.0', '385.0', '210.0', '407.0', '308.0', '302.0', '386.0', '392.0', '413.0', '190.0', '399.0', '245.0', '143.0', '175.0', '163.0', '202.0', '123.0', '166.0', '193.0', '214.0', '459.0', '104.0', '208.0', '312.0', '408.0', '434.0', '109.0', '423.0', '134.0', '183.0', '363.0', '178.0', '384.0', '395.0', '492.0', '228.0', '381.0', '397.0', '107.0', '151.0', '478.0', '402.0', '457.0', '168.0', '218.0', '421.0', '398.0', '174.0', '415.0', '222.0', '417.0', '160.0', '348.0', '94.0', '95.0', '137.0', '76.0', '153.0', '152.0', '382.0', '436.0', '156.0', '431.0', '649.0', '572.0', '391.0', '157.0', '470.0', '432.0', '435.0', '68.0', '508.0', '83.0', '144.0', '438.0', '422.0', '170.0', '46.0', '142.0', '476.0', '133.0', '406.0', '404.0', '120.0', '440.0', '180.0', '429.0', '159.0', '376.0', '458.0', '387.0', '456.0', '403.0', '138.0', '449.0', '679.0', '573.0', '442.0', '176.0', '74.0', '460.0', '672.0', '201.0', '139.0', '445.0', '427.0', '93.0', '126.0', '73.0', '105.0', '450.0', '96.0', '437.0', '472.0', '147.0', '145.0', '430.0', '64.0', '103.0', '136.0', '141.0', '444.0', '155.0', '27.0', '443.0', '439.0', '61.0', '405.0', '448.0', '97.0', '72.0', '98.0', '420.0', '895.0', '700.0', '412.0', '433.0', '428.0', '121.0', '101.0', '451.0', '102.0', '425.0', '466.0', '112.0', '424.0', '65.0', '165.0', '119.0', '89.0', '482.0', '553.0', '498.0', '150.0', '474.0', '765.0', '650.0', '115.0', '999.0', '100.0', '524.0', '21.0', '447.0', '465.0', '462.0', '418.0', '446.0', '479.0', '19.0', '108.0', '149.0', '117.0', '113.0', '127.0', '461.0', '626.0', '544.0', '110.0', '454.0', '475.0', '114.0', '506.0', '467.0', '455.0', '500.0', '41.0', '0.0', '128.0', '507.0', '841.0', '705.0', '495.0', '471.0', '501.0', '693.0', '607.0', '743.0', '497.0', '491.0', '75.0', '510.0', '106.0', '71.0', '131.0', '504.0', '84.0', '464.0', '452.0', '513.0', '519.0', '86.0', '483.0', '43.0', '694.0', '92.0', '511.0', '87.0', '80.0', '489.0', '562.0', '873.0', '561.0', '481.0', '484.0', '493.0', '502.0', '555.0', '547.0', '534.0', '554.0', '453.0', '494.0', '496.0', '116.0', '499.0', '480.0', '545.0', '539.0', '581.0', '646.0', '531.0', '529.0', '122.0', '516.0', '469.0', '541.0', '664.0', '473.0', '528.0', '560.0', '91.0', '530.0', '575.0', '99.0', '509.0', '579.0', '698.0', '985.0', '490.0', '486.0', '601.0', '592.0', '488.0', '47.0', '477.0', '522.0', '521.0', '558.0', '16.0', '810.0', '771.0', '487.0', '78.0', '536.0', '81.0', '518.0', '505.0', '566.0', '523.0', '546.0', '503.0', '525.0', '556.0', '568.0', '583.0', '576.0', '512.0', '515.0', '557.0', '24.0', '90.0', '863.0', '590.0', '844.0', '532.0', '594.0', '600.0', '485.0', '77.0', '538.0', '520.0', '543.0', '603.0', '582.0', '611.0', '45.0', '598.0', '514.0', '551.0', '517.0', '533.0', '878.0', '88.0', '548.0', '663.0', '857.0', '550.0', '563.0', '526.0', '67.0', '585.0', '689.0', '617.0', '720.0', '559.0', '527.0', '903.0', '796.0', '70.0', '10.0', '935.0', '85.0', '63.0', '909.0', '50.0', '39.0', '52.0', '773.0', '619.0', '697.0', '60.0', '744.0', '644.0', '53.0', '13.0', '59.0', '58.0', '82.0', '793.0', '653.0', '66.0', '751.0', '2.0', '724.0', '774.0', '51.0', '57.0', '680.0', '7.0', '787.0', '42.0', '44.0', '29.0', '32.0', '542.0', '31.0', '69.0', '56.0', '629.0', '831.0', '535.0', '49.0', '749.0', '659.0', '55.0', '624.0', '887.0', '540.0', '782.0', '962.0', '37.0', '25.0', '602.0', '767.0', '79.0', '840.0', '552.0', '707.0', '588.0', '735.0', '980.0', '40.0', '23.0', '690.0', '593.0', '580.0', '637.0', '54.0', '587.0', '932.0', '62.0', '48.0', '634.0', '776.0', '836.0', '685.0', '35.0', '570.0', '719.0', '795.0', '834.0', '868.0', '549.0', '537.0', '942.0', '574.0', '865.0', '577.0', '571.0', '589.0', '764.0'])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.vocab.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[228., 327., 315., 401., 203., 324., 319., 207., 418., 250., 233., 348.,\n",
       "         244., 291., 422., 216., 372., 403., 234., 358., 340., 840., 386., 266.,\n",
       "         324., 341., 280., 288., 409., 221., 411., 213., 393., 292., 358., 247.,\n",
       "         285., 185., 376., 393., 311., 411., 425., 274., 248.]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_windows1_disc[4980]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[267., 250., 238., 290., 211., 298., 151., 338., 261., 303., 320., 255.,\n",
       "         179., 311., 218., 306., 213., 230., 298., 999., 348., 346., 281., 311.,\n",
       "         185., 349., 315., 196., 272., 215., 257., 349., 255., 217., 354., 310.,\n",
       "         349., 232., 248., 303., 227., 164., 282., 306., 301.]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_windows2_disc[4980]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec1 = get_sum_repr(train_windows1_disc[4980], model)\n",
    "vec2 = get_sum_repr(train_windows2_disc[4980], model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.9212485]], dtype=float32)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "cosine_similarity(vec1.reshape(1,-1), vec2.reshape(1,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_sum_repr(ts, model):\n",
    "    mat = np.array([model.wv[str(item)] for item in ts.cpu().numpy().reshape(-1)])\n",
    "    mat = mat.max(0)\n",
    "    return mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.3 64-bit ('python36': conda)",
   "language": "python",
   "name": "python36364bitpython36conda9488ed586bcc4bdeab5df32bb542d026"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
